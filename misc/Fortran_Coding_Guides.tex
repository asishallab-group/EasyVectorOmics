\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\geometry{margin=2.5cm}

\usepackage{xcolor}   % for custom link color
\usepackage{hyperref} % force-load to enable \hypersetup

\definecolor{linkblue}{RGB}{0, 0, 238} % classic hyperlink blue

\hypersetup{
colorlinks=true,
urlcolor=linkblue,
linkcolor=linkblue,
citecolor=black
}

\title{F42: Fortran coding guides}
\author{Asis Hallab, ``el Bobito''}

\begin{document}

\maketitle

\tableofcontents
\vspace{1cm}

\newpage
\section{Use latest gfortran compiler version}

To ensure optimal performance and compatibility, always use the latest stable version of the gfortran compiler (15+). 

\noindent We recommend adding a PPA (Personal Package Archive) to your system to easily install the latest version. If you are using Ubuntu, you can do this by running:
\begin{verbatim}
sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install gfortran-<version> # e.g., gfortran-15 
\end{verbatim}

\noindent If gfortran-15 is not available, you can also get the latest version with Docker: 
{\begin{itemize}
  \item Install and setup Docker as explained for your operating system in the Docker documentation.
  \item Use our \href{https://gitlab.rlp.net/a.hallab/tensor-omics/-/blob/main/misc/gfortran.docker?ref_type=heads}{Dockerfile gfortran.docker}: 
  \begin{verbatim}
    docker build -t arch-gfortran -f gfortran.docker . 
  \end{verbatim}
  \item Then build the project with:
  \begin{verbatim}
    docker run -it -v `pwd`:/opt arch-gfortran '/opt/build.sh'
  \end{verbatim}
\end{itemize}}

\section{Use of double precision}

Declare in Fortran internal functions and subroutines \texttt{real} variables and constants always using the ISO double precision standard (see below for an example). Do make sure that if you assign values at compile time, so constants, you \emph{must use} the \texttt{\_real64} suffix to guarantee precision (see example below).

\begin{verbatim}
program double_precision_example
  use, intrinsic :: iso_fortran_env, only: real64  ! Use explicit ISO-standard double precision
  implicit none

  real(real64) :: x, y, result

  ! Assign values
  x = 3.141592653589793_real64
  y = 2.718281828459045_real64

  ! Perform computation
  result = x * y

  ! Print with full precision
  print "(A, F24.16)", "Result = ", result

end program double_precision_example
\end{verbatim}

\section{Using \texttt{test suite framework} for Testing}

This framework provides a robust and scalable system for organizing and executing unit tests in Fortran. It allows running individual tests, complete test suites, or all project tests with simple and clear syntax.

\noindent Please check \href{https://gitlab.rlp.net/a.hallab/tensor-omics/-/tree/main/test?ref_type=heads}{this readme file} for details.

\subsection{Do not test multiple times}

The correctness of the calculation, the correctness of the implemented algorithm is \emph{only} tested in Fortran.

\noindent The API language tests for R, Python, and, if we ever included them, in C should only test that the function can be correctly called and the return values are accessible and of the expected type.

\noindent In other words, do not repeat tests, if avoidable.

\noindent If your test is created by an AI from the original Fortran code, and you thus do not lose work time on writing the test again in another programming language, please do feel free to do so.


\section{Obligatory use of \texttt{intent} and \texttt{pure} }
\begin{itemize}
  \item Always use \texttt{intent} for function or subroutine arguments.
    Be aware of the kind of data being passed.

  \begin{itemize}
    \item \textbf{intent(in)}: Use when the pointer's contents are only read.
    \item \textbf{intent(out)}: Use when the contents will be entirely overwritten.
    \item \textbf{intent(inout)}: Use when the subroutine both reads and writes to the data, and the initial values are important.
  \end{itemize}
  \item Always use \texttt{pure} where possible.
\end{itemize}


\subsection{Optional Arguments in Fortran}

\subsubsection{Overview}

Fortran (ISO standard, since Fortran 90) supports \texttt{optional} procedure arguments, which allow the caller to omit certain arguments when invoking a subroutine or function. Their presence must be checked explicitly using the intrinsic function \texttt{PRESENT}. Fortran does not support default values in procedure headers. Developers must assign defaults manually.

\subsubsection{Syntax and Usage}

To declare an optional argument:

\begin{verbatim}
subroutine example(a, b, c)
  integer, intent(in) :: a
  real, intent(in), optional :: b, c
\end{verbatim}

To check whether an optional argument was passed:

\begin{verbatim}
  if (present(b)) then
    print *, 'B is provided: ', b
  else
    print *, 'B is not provided.'
  end if
\end{verbatim}

\subsubsection{Example}

\begin{verbatim}
program optional_demo
  call greet("Josef")
  call greet("Josef", "Mexico")
contains
  subroutine greet(name, location)
    character(len=*), intent(in) :: name
    character(len=*), intent(in), optional :: location

    print *, "Hello, ", name
    if (present(location)) then
      print *, "How is the weather in ", location, "?"
    end if
  end subroutine greet
end program optional_demo
\end{verbatim}

\subsubsection{Default Value Handling}

Fortran does not support assigning default values directly in the argument list. Instead, assign them manually after a \texttt{PRESENT} check:

\begin{verbatim}
subroutine greet(name, title)
  character(len=*), intent(in) :: name
  character(len=*), intent(in), optional :: title
  character(len=20) :: effective_title

  if (present(title)) then
    effective_title = title
  else
    effective_title = "Mr./Ms."
  end if

  print *, "Hello, ", trim(effective_title), " ", trim(name)
end subroutine greet
\end{verbatim}

\subsubsection{Workaround: Interface Overloading}

To emulate default arguments, use multiple procedures with an interface:

\begin{verbatim}
module greeter_mod
contains
  subroutine greet1(name)
    character(len=*), intent(in) :: name
    call greet2(name, "Mr./Ms.")
  end subroutine

  subroutine greet2(name, title)
    character(len=*), intent(in) :: name
    character(len=*), intent(in) :: title
    print *, "Hello, ", trim(title), " ", trim(name)
  end subroutine
end module

program main
  use greeter_mod
  interface greet
    module procedure greet1, greet2
  end interface

  call greet("Josef")
  call greet("Josef", "Dr.")
end program
\end{verbatim}

\subsubsection{Best Practices}

\begin{itemize}
  \item Always check optional arguments with \texttt{PRESENT} before accessing them.
  \item Avoid relying on optional arguments for critical logic without default assignment.
  \item Use interface overloading to simulate default values if needed for cleaner calling code.
  \item Do not use optional arguments in \texttt{elemental} procedures (not supported).
  \item Document the behavior and defaults of optional arguments clearly in the procedure's interface documentation.
\end{itemize}

\section{Documenting Fortran Code with FORD}

\textbf{FORD} (Fortran Documentation Generator) is a modern tool for generating web and PDF documentation from structured comments in Fortran code. It creates navigable documentation with cross-references, module and subroutine descriptions, argument lists, and usage examples.

\subsection{Basic principles}
\begin{itemize}
  \item Use special comments (\texttt{!>} and \texttt{!|}) to annotate modules, subroutines, functions, and variables.
  \item Comments must be placed immediately before the entity they document.
  \item It is recommended to document all arguments, the general purpose, and any relevant side effects.
\end{itemize}
\begin{itemize}
  \item Use \texttt{!>} for general descriptions of modules, subroutines, and functions.
  \item Use \texttt{!|} to document each argument.
  \item If relevant, add usage examples and warnings with \texttt{!!}.
  \item Keep documentation up to date when the interface changes.
  \item Generate documentation with FORD regularly and review the HTML output.
\end{itemize}
\subsection{Minimal example}
\begin{verbatim}
!> Module for calculating normalized tissue (axis) versatility.
module avmod
  use, intrinsic :: iso_fortran_env, only: real64
  implicit none
contains

  !> Computes normalized tissue versatility for selected expression vectors.
  !! The metric is based on the angle between each gene expression vector and the space diagonal.
  pure subroutine compute_tissue_versatility(n_axes, n_vectors, expression_vectors, &
                                             exp_vecs_selection_index, axes_selection, &
                                             tissue_versatilities, tissue_angles_deg)
    !| Number of axes (tissues/dimensions)
    integer, intent(in) :: n_axes
    !| Number of expression vectors (genes)
    integer, intent(in) :: n_vectors
    !| 2D array (n_axes, n_vectors), each column is a gene expression vector
    real(real64), intent(in) :: expression_vectors(n_axes, n_vectors)
    !| Logical array (n_vectors), .TRUE. for vectors to process
    logical, intent(in) :: exp_vecs_selection_index(n_vectors)
    !| Logical array (n_axes), .TRUE. for axes to include in calculation
    logical, intent(in) :: axes_selection(n_axes)
    !| Output, real array, length = count(exp_vecs_selection_index), stores the calculated 
       tissue versatilities
    real(real64), intent(out) :: tissue_versatilities(count(exp_vecs_selection_index))
    !| Output, real array, length = count(exp_vecs_selection_index), stores the calculated 
       angles in degrees
    real(real64), intent(out) :: tissue_angles_deg(count(exp_vecs_selection_index))
    ! ...
  end subroutine compute_tissue_versatility
end module avmod
\end{verbatim}

\subsection{How to generate documentation}
\begin{enumerate}
  \item Run \texttt{ford ford.yml} in the project root.
  \item Open the generated HTML file (\texttt{doc/index.html}) in your browser.
\end{enumerate}



\section{Fortran to other programming languages Interface}

Ideally, we build our Tensor Omics and F42 code so that it can be included and
called from any other programming language. This comprises R, of course, but
also Python, Lua, Julia, Matlab, etc. We can easily achieve this by offering
two interface functions for every Tensor Omics or F42 function that we
implement. Importantly, we should implement such pure Fortran functions in
Fortran \texttt{module}s. Then add another function of the same name with
appended ``\texttt{\_R}'' to expose the module function to R and a
\texttt{bind(C)} with \texttt{use\_iso\_c\_binding} and naming the function
with appended ``\texttt{\_C}''. See the below example for clarification.

\begin{verbatim}
! High-performance module code
module tensor_omics
contains
  subroutine project_vector_core(v, n)
    real(real64), intent(inout) :: v(n)
    integer, intent(in) :: n
    ! core vector projection logic
  end subroutine
end module

! R interface
subroutine project_vector_R(v, n)
  real(real64) :: v(*)
  integer :: n
  use tensor_omics
  call project_vector_core(v, n)
end subroutine

! C / WASM / Python interface
subroutine project_vector_C(v, n) bind(C, name="project_vector_C")
  use iso_c_binding
  real(c_double) :: v(*)
  integer(c_int) :: n
  use tensor_omics
  call project_vector_core(v, n)
end subroutine
\end{verbatim}

These distinctions are essential for both performance and correctness. Please document this behavior in all wrapper comments.

\subsubsection{Important note on memory and array copies:}

\begin{itemize}
  \item \textbf{R wrappers:} When calling Fortran routines from R (using wrappers with the ``\texttt{\_R}'' suffix), the R interface will \emph{always} create a copy of the arrays passed as arguments. This is a fundamental property of the R--Fortran interface and ensures that the original R objects remain unchanged. Therefore, the following statement must be included in the documentation of every wrapper:
  \textbf{When using these R wrapper functions, copies of the arrays will be created. No direct modification of the original R objects occurs.}
  \item \textbf{C wrappers:} When calling Fortran routines from C (using wrappers with the ``\texttt{\_C}'' suffix and \texttt{bind(C)}), the interface operates \emph{directly} on the memory provided by the caller. Therefore, the following statement must be included in the documentation of every wrapper:
  \textbf{When using these C wrapper functions, no copies of the arrays will be created. The Fortran routine will operate directly on the memory provided by the caller.}
\end{itemize}

You may add these legends manually, or for convenience, use the snippets \verb|tox:legend_r| and \verb|tox:legend_c| found in \verb|snippets/tox_snippets.json|.


\subsection{When to Write Wrappers for Fortran Functions}

Only write wrappers for Fortran functions and subroutines that provide truly new or essential functionality to the API languages (C, R). For example, generic utilities such as sorting, which are already well-supported in most high-level languages, should not be wrapped unless there is a compelling reason. Focus on exposing the core scientific Tensor Omics or F42 functions.

\subsection{The \texttt{\_tox} API Layer: Safe Data Access and Usage}

In addition to the standard wrappers, we will implement another layer of API functions, conventionally named with the suffix \texttt{\_tox}, that are designed to operate using a pointer to our \texttt{txdata} Fortran type. This approach allows for efficient and direct manipulation of complex data structures from API languages, while maintaining safety and clarity.

It is good practice to expose all relevant Fortran routines, but in the user manual and documentation, we will emphasize the use of the \texttt{\_tox} interface for most users. This interface is safer and more robust, as it manages the internal data structures and memory correctly. Direct access to lower-level routines is possible, but should be used with caution: the user must ensure that arrays or pointers passed to Fortran are not modified elsewhere (e.g., by libraries like matplotlib or numpy) while Fortran code is using them, to avoid undefined behavior or memory corruption.

\textbf{Documentation guideline:} In the manual, show usage examples of the \texttt{\_tox} interface as the recommended way, and only mention that direct calls are possible for advanced users who understand the risks and memory management requirements.

\textbf{Example:} The \texttt{analyze\_tox} function takes a pointer to a \texttt{txdata} object and performs analysis, ensuring all memory and data integrity is managed by the Fortran backend. Direct calls to lower-level routines should be clearly marked as advanced usage.


\subsection{Safe and Efficient Interface Design for \texttt{bind(C)} in Tensor Omics}


To expose Tensor Omics routines safely and portably, we use minimal \texttt{bind(C)} wrappers around internal Fortran procedures. Each wrapper is designed for ABI stability, no-copy interop, and zero semantic loss.

\subsubsection{Keep \texttt{bind(C)} wrappers minimal}

Wrap only, no computation.

\begin{verbatim}
subroutine project_vector_C(x, n) bind(C, name="project_vector_C")
  use iso_c_binding
  real(c_double) :: x(*)
  integer(c_int) :: n
  call project_vector_core(x, n)
end subroutine
\end{verbatim}

\subsubsection{Use \texttt{iso\_c\_binding} types}

Avoid compiler-specific kinds.

\begin{verbatim}
real(c_double) :: x(*)
integer(c_int) :: n
\end{verbatim}

\subsubsection{Accept arguments as C-style pointers}

Do not use assumed-shape or allocatable arrays.

\begin{verbatim}
real(c_double) :: x(*)      ! OK
real(c_double), dimension(:) :: x  ! Not allowed
\end{verbatim}

\subsubsection{Avoid optional arguments}

Optional arguments are not allowed in R and C wrappers because \texttt{bind(C)} and \texttt{.Fortran()} are not compatible with them. If optional arguments are needed, they should only be used in core subroutines that are called directly from Fortran. 

\subsubsection{Pass all arguments by reference}

Do not use \texttt{value}; pass pointers from caller (Python, Lua, etc.).

\begin{verbatim}
real(c_double) :: x(*)
integer(c_int) :: n
\end{verbatim}

\subsubsection{Preserve SIMD and optimization pathways}

Call computational logic in a separate routine that uses full Fortran features.

\begin{verbatim}
subroutine project_vector_core(x, n)
  real(real64), intent(inout) :: x(n)
  integer, intent(in) :: n
  ! fast loop, vectorizable
end subroutine
\end{verbatim}

\subsubsection{Use stable symbol names}

Avoid compiler-dependent mangling by specifying names explicitly.

\begin{verbatim}
subroutine project_vector_C(x, n) bind(C, name="project_vector_C")
\end{verbatim}

\subsubsection{Ensure ABI compatibility with all consumers}

Expose only basic types: scalars and flat arrays.

\begin{verbatim}
real(c_double) :: vec(*)
integer(c_int) :: n
! No derived types, assumed-shape arrays, or allocatables
\end{verbatim}

\subsubsection{Verify type equivalence when calling core Fortran routines}

Make sure internal types match \texttt{iso\_c\_binding} externally.

\begin{verbatim}
use iso_c_binding
real(real64) :: x(n)
! Ensure real(real64) == real(c_double) on your compiler
\end{verbatim}

\subsubsection{Avoid aliasing in calls to \texttt{bind(C)} routines}

Do not pass the same variable twice under different names.

\begin{verbatim}
! DON'T - Unsafe aliasing: same memory twice
call project_vector_C(x, x, n)

! OK - Pass unique memory regions only
call project_vector_C(x, y, n)
\end{verbatim}

This structure ensures maximum compatibility and reproducibility across calling environments without compromising Fortran-native performance.

\subsection{How to pass arguments back and forth to C, and thus Python, without memory copy.}

When passing arrays or strings between Fortran and C (or Python), you can achieve zero-copy interoperation using the ISO C binding module and pointer association. Below are canonical examples for both arrays and C strings:

\subsubsection*{int, real, logical, complex Fortran assumed shape arrays}

\begin{verbatim}
module interop_example
  use iso_c_binding
  implicit none
contains

! Entry point called from C
subroutine process_int_array(ptr, n, f_arr) bind(C)
  use iso_c_binding
  implicit none
  type(c_ptr), value :: ptr         ! Raw C pointer passed from C
  integer(c_int), value :: n        ! Number of elements

  integer(c_int), pointer :: f_arr(:) ! Fortran pointer to wrap the C array

  ! Convert raw C pointer into a Fortran assumed-shape pointer
  call c_f_pointer(ptr, f_arr, [n])

  ! f_arr can now be passed to any subroutine expecting an assumed-shape array
  call do_work_on_array(f_arr)

end subroutine process_int_array

! This subroutine accepts an assumed-shape array and works with it
subroutine do_work_on_array(arr)
  implicit none
  integer(c_int), intent(inout) :: arr(:)

  integer :: i
  do i = 1, size(arr)
    arr(i) = arr(i) + 1
  end do
end subroutine do_work_on_array

end module interop_example
\end{verbatim}

\subsubsection*{C Strings to Fortran Strings}

This is for C Strings, but should be treated with caution, because the result \textbf{cannot be used as assumed length Fortran chars}.

\begin{verbatim}
module charptr_demo
  use iso_c_binding
  implicit none
contains

subroutine process_c_string(c_str_ptr, str_len) bind(C)
  use iso_c_binding
  implicit none

  ! Arguments from C
  type(c_ptr), value :: c_str_ptr
  integer(c_int), value :: str_len

  ! Fortran pointer to reshape the C char*
  character(kind=c_char), pointer :: str(:)

  ! Map the C pointer to a Fortran pointer
  call c_f_pointer(c_str_ptr, str, [str_len])

  ! NOTE:
  ! The above Fortran pointer can be passed as an assumed shape Array
  ! to any Fortran subroutine or function expecting an assumed shape
  ! argument. Internally they are converted without (much) overhead. 

  ! Print characters one by one (to show contents and no copy)
  print *, 'Received C string (raw char*):'
  print '(a)', str ! Note: prints whole array as string

  ! Optionally: Loop through chars
  ! do i = 1, str_len
  !   write(*,'(a)', advance='no') str(i)
  ! end do
  ! write(*,*)
end subroutine process_c_string

end module charptr_demo
\end{verbatim}

\subsubsection*{Summary Table of Interoperable Array Patterns}

\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Direction} & \textbf{Method} & \textbf{Copy?} & \textbf{Safe?} \\
\hline
C $\rightarrow$ Fortran & \texttt{c\_f\_pointer} & No & Yes \\
Fortran $\rightarrow$ C & \texttt{c\_loc + shape info} & No & Yes \\
Fortran descriptor to C & Not possible & N/A & No \\
Allocatable return & Not portable & Yes (implicit) & No \\
\hline
\end{tabular}
\end{center}

This approach ensures efficient, copy-free interoperation between Fortran and C while preserving the expressiveness of assumed-shape arrays internally in Fortran.

\noindent\textbf{Caller responsibility:}
The external caller (e.g., from C, Python, Lua) must allocate a 1D array of size \texttt{nrow * ncol} and ensure it is stored in Fortran-style column-major order, or reshaped accordingly.

\noindent This pattern allows Tensor Omics to retain full multidimensional structure internally while offering safe and portable interfaces to external consumers.


\section{Fortran Array Notation Cheat-Sheet}

This section summarizes the three common ways to declare array arguments in Fortran procedures, with a focus on their use, safety, and suitability in modern code.

\subsection{1. Assumed-Size Arrays \texttt{(*)}}

\begin{verbatim}
subroutine example(a, n)
  real(real64), intent(in) :: a(*)
  integer, intent(in) :: n
  integer :: i
  do i = 1, n
    print *, a(i)
  end do
end subroutine
\end{verbatim}

\textbf{Meaning:} \texttt{a(*)} is an assumed-size array. The subroutine does not know the array bounds and must be told explicitly via a separate argument (e.g., \texttt{n}). This is the lowest-level array form and maps closely to a raw pointer in C.

\textbf{Limitations:}
\begin{itemize}
  \item No bounds checking
  \item \texttt{size(a)} and \texttt{lbound(a)} are illegal
  \item Cannot use array operations like \texttt{matmul} or \texttt{sum}
  \item Unsafe for slicing (\texttt{a(2:5)} is undefined)
\end{itemize}

\textbf{Use case:} C interoperability, legacy code, low-level memory kernels.


\subsection{2. Assumed-Shape Arrays \texttt{(:)}}

\begin{verbatim}
subroutine example(a)
  real(real64), intent(in) :: a(:)
  integer :: i
  do i = 1, size(a)
    print *, a(i)
  end do
end subroutine
\end{verbatim}

\textbf{Meaning:} \texttt{a(:)} is an assumed-shape array. The compiler receives size and bounds information at runtime. Requires an explicit interface (typically via a module or \texttt{interface} block).

\textbf{Advantages:}
\begin{itemize}
  \item Safe: \texttt{size(a)} is available
  \item Supports slicing, broadcasting, and array intrinsics
  \item Can use \texttt{matmul}, \texttt{dot\_product}, etc.
\end{itemize}

\textbf{Use case:} Recommended default for most modern Fortran code.


\subsection{3. Multidimensional Arrays \texttt{(:,:)} and Higher}

\begin{verbatim}
subroutine process_matrix(A)
  real(real64), intent(in) :: A(:, :)
  print *, size(A, 1), size(A, 2)
end subroutine
\end{verbatim}

\textbf{Meaning:} Each colon represents a dimension of unknown size. Like 1D assumed-shape arrays, this requires an explicit interface and passes shape info at runtime.

\textbf{Features:}
\begin{itemize}
  \item Full array operations: \texttt{transpose}, \texttt{matmul}, etc.
  \item Safer and clearer semantics for tensors and matrices
\end{itemize}

\textbf{Use case:} Tensor Omics vector spaces, image/matrix processing, linear algebra routines.

\vspace{1em}

\noindent\textbf{Summary Table}

\begin{tabular}{|l|l|l|l|}
\hline
Notation & Bounds Known? & Safe? & Use Case \\
\hline
\texttt{(*)} & No  & No  & C interop, low-level \\
\texttt{(:)} & Yes & Yes & Modern Fortran arrays \\
\texttt{(:,:)} & Yes & Yes & Matrices, tensors \\
\hline
\end{tabular}

\noindent For all assumed-shape forms (\texttt{(:)}, \texttt{(:,:)}), ensure the subroutine has an explicit interface or is in a module.


\section{Memory Passing Behavior in Fortran (F42 Standard for Tensor Omics)}

\subsection{General Principles}

In Fortran (standards 77--2018), arguments to subroutines and functions are, by default, passed \textbf{by reference} rather than by copying.  
This applies to scalars, arrays, and derived types.

Thus:

\begin{itemize}
    \item Scalars (e.g., \texttt{integer}, \texttt{real}) are passed by reference.
    \item Arrays (e.g., \texttt{integer, dimension(:)}, \texttt{real, dimension(:,:)}) are passed by reference.
    \item Derived types are passed by reference.
\end{itemize}

\subsection{When Copies Are Made}

Despite the default pass-by-reference behavior, hidden copies may be generated by the compiler in the following situations:

\begin{itemize}
    \item \textbf{Passing expressions}: e.g., \texttt{call process(a+b)} requires evaluation and temporary storage.
    \item \textbf{Passing strided array sections}: e.g., \texttt{array(1:10:2)} is non-contiguous and may trigger copying.
    \item \textbf{Passing non-contiguous slices}: particularly relevant for rows in a 2D array.
\end{itemize}

\subsection{Tensor Omics DataTables: Column and Row Passing}

Tensor Omics DataTables store typed data in 2D Fortran arrays of the form:

\begin{itemize}
    \item \texttt{real\_array(n\_rows, n\_real\_columns)}
    \item \texttt{int\_array(n\_rows, n\_int\_columns)}
    \item \texttt{char\_array(n\_rows, n\_char\_columns)}
\end{itemize}

\textbf{Accessing Columns}:

\begin{itemize}
    \item Example: \texttt{real\_array(:, j)}
    \item Behavior: Passed by reference, \textbf{no copy made}.
    \item Reason: Slicing across the first index in column-major layout yields contiguous memory.
\end{itemize}

\textbf{Accessing Rows}:

\begin{itemize}
    \item Example: \texttt{real\_array(i, :)}
    \item Behavior: Typically triggers a hidden copy.
    \item Reason: Slicing across the second index accesses non-contiguous memory addresses, requiring packing into a contiguous temporary.
\end{itemize}

\subsection{Summary Tables}

\subsubsection{General Fortran Behavior}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Action} & \textbf{Example} & \textbf{Copy Made?} \\
\hline
Pass full array & \texttt{array} & No \\
Pass contiguous slice & \texttt{array(:, j)} & No \\
Pass strided slice & \texttt{array(1:10:2, j)} & Yes \\
Pass expression & \texttt{array(:, j) * 2.0} & Yes \\
\hline
\end{tabular}
\end{center}

\subsubsection{Tensor Omics DataTables Specifics}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Access Type} & \textbf{Example} & \textbf{Copy Made?} \\
\hline
Access full column & \texttt{real\_array(:, j)} & No \\
Access full row & \texttt{real\_array(i, :)} & Yes \\
\hline
\end{tabular}
\end{center}

\subsection{Best Practice Recommendation for Tensor Omics}

\begin{itemize}
    \item Always design core functions to work with columns if possible.
    \item Avoid passing strided slices or expressions directly to subroutines.
    \item Treat rows carefully: copy manually if absolutely needed, otherwise prefer per-element processing.
\end{itemize}

\subsection{Conclusion}

Efficient memory handling is critical for Tensor Omics.  
Understanding Fortran's passing conventions allows maximization of speed, minimization of hidden temporaries, and preservation of F42 computational standards.

\section{Critical Practices in TOX Interfacing and Control Flow}

This section consolidates three key implementation standards for TOX and F42 compliance: correct R–Fortran interfacing, prohibition of \texttt{GOTO}, and manual memory cleanup.

\subsection{Why \texttt{bind(C)} Is Dangerous for R Interfacing}

Using \texttt{bind(C)} in Fortran changes the function's symbol name and calling convention to conform to the C ABI. This is incompatible with R's native \texttt{.Fortran()} interface, which relies on legacy Fortran symbol conventions (e.g., appending underscores, pass-by-address semantics).

\subsubsection*{Problems Caused by \texttt{bind(C)} in R Packages}
\begin{itemize}
  \item \textbf{Breaks Symbol Lookup:} R expects mangled names like \texttt{mysub\_}, which \texttt{bind(C)} suppresses.
  \item \textbf{Incorrect Argument Handling:} Changes to calling convention may result in wrong memory alignment or crashes.
  \item \textbf{Unnecessary:} R handles native Fortran linking automatically during package build.
\end{itemize}

\subsubsection*{Correct Way to Interface R with Fortran}
\begin{enumerate}
  \item Write your subroutines in pure Fortran \emph{without} \texttt{bind(C)}.
  \item Place Fortran files in \texttt{src/} directory of the package.
  \item Register your compiled code using \texttt{useDynLib(pkgname)} in \texttt{NAMESPACE}.
  \item Call Fortran code from R via \texttt{.Fortran()}:
\begin{verbatim}
  result <- .Fortran("mysub",
    as.double(x), as.double(y), result = double(1))$result
\end{verbatim}
\end{enumerate}

\subsubsection*{Minimal Example of Package Setup}
\begin{itemize}
  \item \texttt{DESCRIPTION}: no special flags needed.
  \item \texttt{NAMESPACE}: \verb|useDynLib(mytoxpkg)|
  \item \texttt{src/mysub.f90}:
\begin{verbatim}
subroutine mysub(x, y, result)
  real(real64) :: x, y, result
  result = x + y
end subroutine
\end{verbatim}
\end{itemize}

\vspace{1em}
\subsection{Why \texttt{GOTO} Is Forbidden in F42 and TOX}

\texttt{GOTO} is a low-level control structure that violates the principles of structured, readable, and verifiable code. While allowed by Fortran, its use is incompatible with both modern software engineering and WebAssembly (WASM) compilation.

\subsubsection*{Reasons for Prohibition}
\begin{itemize}
  \item \textbf{Non-Structured Control Flow:} Makes code hard to reason about and maintain.
  \item \textbf{Incompatible With WASM:} WebAssembly requires structured control graphs.
  \item \textbf{Opaque for Debugging:} Introduces implicit jump logic that hinders traceability.
  \item \textbf{Fails F42 Goals:} Violates statelessness, modularity, and verifiability.
\end{itemize}

\subsection{How to Replace \texttt{GOTO} Correctly}

\subsubsection*{1. Use \texttt{exit} to break out of a loop}
\begin{verbatim}
do i = 1, n
  if (array(i) < 0.0) then
    exit
  end if
end do
\end{verbatim}

\subsubsection*{2. Use \texttt{cycle} to skip to next iteration}
\begin{verbatim}
do i = 1, n
  if (.not. valid(i)) cycle
  call process(i)
end do
\end{verbatim}

\subsubsection*{3. Use \texttt{select case} for structured branching}
\begin{verbatim}
select case(code)
case(1)
  call handle_case1()
case(2)
  call handle_case2()
case default
  call handle_default()
end select
\end{verbatim}

\subsection{Memory Cleanup: Manual Destructors}

Since Fortran has no \texttt{try/finally} construct and F42 disallows \texttt{final ::} destructors due to their opacity, all memory cleanup must be performed manually.

\subsubsection*{Pattern: Explicit Cleanup Subroutine}
\begin{verbatim}
subroutine deallocate_datatable(dt)
  type(DataTable), intent(inout) :: dt

  if (allocated(dt%real_array)) deallocate(dt%real_array)
  if (allocated(dt%char_array)) deallocate(dt%char_array)
  if (allocated(dt%int_array))  deallocate(dt%int_array)
  if (allocated(dt%column_names)) deallocate(dt%column_names)
end subroutine
\end{verbatim}

\subsubsection*{Pattern: Simulated try-finally via logical block}
\begin{verbatim}
logical :: success
success = .false.

call allocate_datatable(dt, ierr)
if (ierr == 0) then
  call compute(dt)
  success = .true.
end if

call deallocate_datatable(dt)
\end{verbatim}

\subsection*{Conclusion}

All R–Fortran interfacing, control flow, and memory management in TOX must follow F42 principles:
\begin{itemize}
  \item Never use \texttt{bind(C)} unless wrapping via \texttt{.Call()} (not \texttt{.Fortran()}).
  \item Never use \texttt{GOTO} — always use structured constructs.
  \item Always provide manual cleanup subroutines for types containing allocatables.
\end{itemize}

These principles ensure safety, readability, WASM compatibility, and long-term maintainability.

\section{Scientific Kernel and API Design Specification}

\subsection{Scope}
This specification defines the design principles, coding conventions, and interface structure for the Tensor Omics Scientific Kernel (SK) and its associated API helper layers. The aim is to ensure performance, reproducibility, portability, and clarity of responsibility between computational components.

\subsection{Scientific Kernel (SK)}

\subsubsection{Definition}
The Scientific Kernel consists exclusively of pure Fortran subroutines and functions implementing the numerical and geometric methods of Tensor Omics.

\subsubsection{Core Properties}
\begin{enumerate}
  \item \textbf{Purity:} SK routines must have no side effects beyond modifying their output arguments.
  \item \textbf{No I/O:} SK routines must not perform any file or console I/O.
  \item \textbf{No Dynamic Allocation:} SK routines must not contain any \texttt{allocate} or \texttt{deallocate} statements.
  \item \textbf{Memory Alignment:} All array arguments must be Fortran \texttt{allocatable} arrays to ensure alignment and contiguity.
  \item \textbf{Transient Memory:} Any intermediate (scratch) memory must be preallocated by the caller and passed as arguments.
  \item \textbf{Determinism:} Given the same inputs, SK routines must always return identical outputs.
\end{enumerate}

\subsubsection{Argument Requirements}
\begin{enumerate}
  \item Arrays must be \texttt{allocatable} and contiguous.
  \item All intent must be explicitly declared (\texttt{intent(in)}, \texttt{intent(out)}, \texttt{intent(inout)}).
  \item Kind parameters for floating-point arguments must be specified using \texttt{real64} from \texttt{iso\_fortran\_env}.
\end{enumerate}

\subsection{Helper Routines}

\subsubsection{Purpose}
Helper routines manage memory allocation, type handling, and API exposure for SK routines. They may have side effects such as allocation or type conversion.

\subsubsection{Naming Convention}
Helper routines follow suffix-based naming to indicate their role:
\begin{itemize}
  \item \textbf{No suffix:} Pure SK routine.
  \item \textbf{\_alloc:} Allocation helper that computes required sizes and allocates memory.
  \item \textbf{\_C:} C-facing API wrapper exposing SK routines via \texttt{bind(C)} and \texttt{iso\_c\_binding}.
  \item \textbf{\_R:} R-facing API wrapper calling SK routines via \texttt{.Fortran} or \texttt{.Call}.
  \item \textbf{\_tox:} Helper operating on the \texttt{tox\_data} derived type.
  \item \textbf{\_tox\_C:} C-facing API wrapper for a \_tox helper.
  \item \textbf{\_helper:} General-purpose orchestration helper not bound to a specific API.
\end{itemize}

\subsubsection{Module Organization}
\begin{enumerate}
  \item All SK and helper routines reside in the same Fortran module for discoverability.
  \item Naming conventions are strictly enforced to distinguish pure SK code from helpers.
  \item Helpers may call SK routines or other helpers but must not duplicate SK logic.
\end{enumerate}

\subsection{API Exposure Layers}

\subsubsection{C API (\_C, \_tox\_C)}
\begin{enumerate}
  \item Implemented using \texttt{bind(C)} and \texttt{iso\_c\_binding}.
  \item Accept and return only C-interoperable types.
  \item May perform allocation if required.
  \item Designed to be callable directly from C, Python (via \texttt{ctypes} or \texttt{cffi}), and other C-compatible languages.
\end{enumerate}

\subsubsection{R API (\_R)}
\begin{enumerate}
  \item Implemented as R functions calling \texttt{.Fortran} for direct array access.
  \item \texttt{.Fortran} calls may incur data copying and cannot pass pointers directly.
  \item \textbf{Note} that we will implement a thin \texttt{C glue layer} to
    expose the above `\_tox\_C` helpers to R and enable pointer passing.
\end{enumerate}

\subsection{tox\_data Type}

\subsubsection{Purpose}
A Fortran derived type \texttt{tox\_data} serves as a container for all related Tensor Omics datasets, ensuring data integrity and preventing unintentional modification from higher-level languages.

\subsubsection{Access Policy}
\begin{enumerate}
  \item Access to \texttt{tox\_data} contents is via getter functions.
  \item Setter functions might be provided but discouraged for normal use. As
    we expose the scientific kernel functions directly, users who want to be
    able to modify expression-vectors, family-centroids, or similar will be
    required to manage memory and their data manually.
  \item Rich querying is provided via a GraphQL interface. We might implement a
    `jq` interface on top of that, too.
\end{enumerate}

\subsection{Coarray Considerations}
\begin{enumerate}
  \item SK routines are compatible with coarrays as they operate on preallocated, caller-provided memory.
  \item C API wrappers do not expose coarrays; coarray usage requires direct Fortran coding by the user.
\end{enumerate}

\subsection{WebAssembly (WASM) Considerations}
\begin{enumerate}
  \item SK routines are compilable to WASM as they are pure and self-contained.
  \item API helpers may require adaptation or (most likely) exclusion depending
    on WASM environment capabilities. This can be done via Fortran precompiler
    flag usage:
\begin{verbatim}
#ifndef WASM
subroutine family_centroid_alloc(...)
  ! ...
end subroutine family_centroid_alloc
#endif
\end{verbatim}
\end{enumerate}

\subsection{Enforcement}
\textbf{Naming conventions must be validated during peer revision.}

\section{High-Performance Fortran Compilation and Memory Alignment}

\textbf{Note that this section is largely deprecated, except the Coarray
section and the content on how to optimize for certain compilers and hardware.
But we likely want to avoid such manual optimizations.}

This section provides practical guidelines for scientific programmers to write memory-efficient and performance-optimized Fortran code using OpenMP, SIMD, and compiler-specific features. It also includes instructions on compiler configuration and memory alignment strategies suitable for AVX2 and AVX-512 systems.

\subsection{Precompiler include file for constants}

We need a precompiler macros file that needs to be included in all Fortran
files that use macros.

\vspace{1em}%
\noindent{}File \texttt{precompiler\_constants.F90}:
\begin{verbatim}
#ifndef DEFAULT_ALIGNMENT
#define DEFAULT_ALIGNMENT 32
#endif
\end{verbatim}

\subsection{OpenMP and SIMD: Double Parallelization}
\label{thread_and_vectorized_parallelization}
Modern Fortran compilers support combined OpenMP threading and SIMD vectorization through a single directive:

\begin{verbatim}
!$omp parallel do simd schedule(static) private(i)
do i = 1, n
a(i) = b(i) + c(i)
end do
!$omp end parallel do simd
\end{verbatim}

This pragma enables:
\begin{itemize}
\item \textbf{Thread-level parallelism} via OpenMP.
\item \textbf{Instruction-level parallelism} via SIMD (Single Instruction, Multiple Data).
\end{itemize}

This combination splits loop iterations across threads, and each thread processes elements in SIMD fashion. It is ideal for dense numerical operations.

\subsection{Compiler-Specific Pragmas and Flags}

To \emph{ensure} the above OpenMP \emph{and} vectorized parallelization (see
\ref{thread_and_vectorized_parallelization}) works with maximum efficiency, we
need to use compiler pragmas for Intel and gfortran compilers. See this example
that tells both compilers that the Arrays used in the \texttt{do}-loop actually
are setup correctly for vectorized (\texttt{SIMD}) parallelization on the level
of the CPU:

\begin{verbatim}
!DIR$ ASSUME_ALIGNED a:64, b:64, c:64
!$omp parallel do simd schedule(static) private(i) aligned(a, b, c:64)
do i = 1, n
  a(i) = b(i) + c(i)
end do
!$omp end parallel do simd
\end{verbatim}

The above ensures most efficient compilation, if and only if the right compiler
flags are set (see below sections \ref{intel_flags} and \ref{gfortran_flags}),
too.

\subsubsection{How to optimize for all CPU architectures?}
\label{simd_architecture_macros}

The problem here is that the above \texttt{memory alignment boundary in bytes}
set to 64 depends on the CPU vectorized instruction set, i.e. \texttt{AVX2},
\texttt{AVX512}, etc. So, we need to do some macro magic to squeeze the last
bit of maximum efficency out of our code for any hardware it is compiled on:

\begin{verbatim}
! The below line should likely be the first line
! in any Fortran file that has macros.
#include "precompiler_constants.F90"

! This included module sets the correct memory alignment boundary in bytes
! and ensures that when allocating arrays in Fortran they are correctly aligned.
use config

#if DEFAULT_ALIGNMENT == 16
!DIR$ ASSUME_ALIGNED a:16, b:16, c:16
!$omp parallel do simd schedule(static) private(i) aligned(a, b, c:16)
#elif DEFAULT_ALIGNMENT == 32
!DIR$ ASSUME_ALIGNED a:32, b:32, c:32
!$omp parallel do simd schedule(static) private(i) aligned(a, b, c:32)
#elif DEFAULT_ALIGNMENT == 64
!DIR$ ASSUME_ALIGNED a:64, b:64, c:64
!$omp parallel do simd schedule(static) private(i) aligned(a, b, c:64)
#elif DEFAULT_ALIGNMENT == 128
!DIR$ ASSUME_ALIGNED a:128, b:128, c:128
!$omp parallel do simd schedule(static) private(i) aligned(a, b, c:128)
#else
!$omp parallel do simd schedule(static) private(i)
#endif

do i = 1, n
  a(i) = b(i) + c(i)
end do
!$omp end parallel do simd
\end{verbatim}

\emph{Note} see section \ref{fortran_config_module} for the above
\texttt{config} module, please.

\subsubsection{OpenMP Variable Scoping: \texttt{private} and \texttt{reduction}}

When using OpenMP parallel loops, it is essential to correctly declare the scope of all variables used within the loop body. This ensures thread safety and avoids unintended data races or compiler misoptimizations.

Most importantly:

\begin{itemize}
  \item \textbf{Loop indices} must be declared as \texttt{private}, e.g., \texttt{private(i)}.
  \item \textbf{Temporary variables or accumulators} introduced inside the loop body must also be marked \texttt{private}, unless they are used in a reduction.
  \item \textbf{Reduction variables} (e.g., sums or maxima computed across threads) must be declared using the \texttt{reduction(...)} clause.
\end{itemize}

\noindent
Example:
\begin{verbatim}
real(real64) :: tmp
real(real64) :: sum

!$omp parallel do simd private(i, tmp) reduction(+:sum) schedule(static)
do i = 1, n
  tmp = compute(i)
  sum = sum + tmp
end do
!$omp end parallel do simd
\end{verbatim}

In this example:
\begin{itemize}
  \item \texttt{i} is the loop counter and must be private.
  \item \texttt{tmp} is a per-iteration local value and must be private to avoid race conditions.
  \item \texttt{sum} is a global accumulator and must be declared as a reduction variable with the \texttt{+} operator.
\end{itemize}

Failing to properly scope these variables may lead to undefined behavior, wrong results, or silent compiler fallbacks to scalar execution. Always carefully inspect variable use when applying OpenMP to numerical loops.

\subsubsection{Reduction Operations in OpenMP SIMD Loops}

When performing numerical or logical accumulation in parallel regions, OpenMP provides \texttt{reduction} clauses that ensure correctness and performance across threads. These clauses combine thread-local results using an associative operation into a final value at the end of the parallel loop.

\vspace{1em}
\noindent
\textbf{Supported Reduction Operations in OpenMP:}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Operation} & \textbf{Description} & \textbf{Example} \\
\hline
\texttt{+} & Sum & \texttt{reduction(+:sum)} \\
\texttt{*} & Product & \texttt{reduction(*:prod)} \\
\texttt{max} & Maximum value & \texttt{reduction(max:maxval)} \\
\texttt{min} & Minimum value & \texttt{reduction(min:minval)} \\
\texttt{-} & Subtraction\textsuperscript{*} & \texttt{reduction(-:diff)} \\
\hline
\texttt{iand} & Bitwise AND (integers) & \texttt{reduction(iand:mask)} \\
\texttt{ior} & Bitwise OR (integers) & \texttt{reduction(ior:flag)} \\
\texttt{ieor} & Bitwise XOR (integers) & \texttt{reduction(ieor:flag)} \\
\hline
\texttt{.and.} & Logical AND (booleans) & \texttt{reduction(.and.:ok)} \\
\texttt{.or.} & Logical OR (booleans) & \texttt{reduction(.or.:status)} \\
\hline
\end{tabular}
\end{center}

\vspace{1em}
\noindent
\textbf{Note:}
\begin{itemize}
\item Most common are \texttt{+}, \texttt{max}, and \texttt{min} for numerical accumulations.
\item The subtraction operator \texttt{-} is supported, but caution is advised: subtraction is not associative, so the result may depend on thread order. Use only if mathematically justified.
\item Logical and bitwise reductions are especially useful for flags, masks, and status checks.
\end{itemize}

\noindent
\textbf{Best practice:} Always declare temporary or accumulator variables as \texttt{private(...)} or \texttt{reduction(...)} depending on their intended aggregation behavior. This prevents race conditions and ensures correctness.

\subsubsection{Intel Compiler (\texttt{ifort} or \texttt{ifx})}
\label{intel_flags}
Recommended flags:
\begin{verbatim}
-O3 -qopenmp -xHost -align array64byte -qopt-zmm-usage=high -qopt-prefetch=3 -qopt-matmul -fPIC
\end{verbatim}

\subsubsection{GNU Compiler (\texttt{gfortran})}
\label{gfortran_flags}
Recommended flags:
\begin{verbatim}
-O3 -march=native -mtune=native -fopenmp -ffast-math -funroll-loops -ftree-vectorize 
-fassociative-math -fPIC
\end{verbatim}

\subsection{Configuring \texttt{fpm.toml}}

\begin{verbatim}
name = "tensor-omics"
version = "0.1.0"
license = "MIT"

[install]
library = true

[library]
type = "shared" 
\end{verbatim}

\subsection{Compile Script with Hardware-Dependent Defaults}
Use a compile script to choose the optimal alignment at runtime and apply the appropriate compiler profile:

\begin{verbatim}
#!/bin/bash
# build.sh | Optimized build script for FPM with dynamic alignment
# Default fallback alignment for the most likely situation:
ALIGN=32
# Detect capabilities in order of descending priority:
if lscpu | grep -q amx; then
ALIGN=128
elif lscpu | grep -q avx512; then
ALIGN=64
elif lscpu | grep -q avx2; then
ALIGN=32
elif lscpu | grep -q sse2; then
ALIGN=16
fi
# Detect compiler and choose appropriate profile:
if [[ "$FC" == "ifx" || "$FC" == "ifort" ]]; then
  FLAGS="-O3 -qopenmp -xHost -align array64byte -qopt-zmm-usage=high -qopt-prefetch=3 -qopt-matmul 
  -fPIC"
  COMPILER="ifx"
else
  FLAGS="-O3 -march=native -mtune=native -fopenmp -ffast-math -funroll-loops -ftree-vectorize 
  -fassociative-math -fPIC"
  COMPILER="gfortran"
fi

# Detect --max-performance flag
MAX_PERF_FLAG=""
for arg in "$@"; do
  if [[ "$arg" == "--max-performance" ]]; then
    MAX_PERF_FLAG="-DMAX_PERFORMANCE"
  fi
done

# Informative output:
# Build with selected profile and alignment parameter:
export FC
fpm build --compiler $COMPILER --flag "$FLAGS" --flag "-DDEFAULT_ALIGNMENT=$ALIGN" 
          --flag "$MAX_PERF_FLAG"

echo "Build complete with compiler: $COMPILER, alignment: $ALIGN bytes, optimization flags: $FLAGS, 
      max performance: $MAX_PERF_FLAG"

# Find .so file in the build directory
sofile=$(find build -name 'libtensor-omics.so' | head -n 1)

# Create symbolic link in the build directory with relative path
if [[ -n "$sofile" ]]; then
  # Extract the relative path from build/ directory
  relative_path=$(realpath --relative-to=build "$sofile")
  ln -sf "$relative_path" build/libtensor-omics.so
  echo "Created symlink: build/libtensor-omics.so -> $relative_path"
else
  echo "Warning: libtensor-omics.so not found in build directory"
fi
\end{verbatim}

\subsection{Contiguous and Aligned Arrays in Fortran}
A \texttt{contiguous} array is one whose elements are stored sequentially in memory. An \texttt{aligned} array is one that starts at a memory address that is a multiple of the desired alignment boundary (e.g., 32 or 64 bytes).

\textbf{All \texttt{allocatable} arrays in Fortran are inherently contiguous.} Aligned allocation ensures that SIMD instructions can operate efficiently.

\subsection{Configuration Module}
\label{fortran_config_module}
\begin{verbatim}
#include "precompiler_constants.F90"

module config
implicit none
#ifdef DEFAULT_ALIGNMENT
integer, parameter :: alignment = DEFAULT_ALIGNMENT
#endif
end module config
\end{verbatim}

\subsection{Alignment-Aware Padding Function}
This helper computes padded sizes for any array dimension:

\begin{verbatim}
module alignment_utils
use config
implicit none
contains

integer function padded_size(n)
integer, intent(in) :: n
padded_size = alignment * ceiling(real(n) / alignment)
end function padded_size

end module alignment_utils
\end{verbatim}

Use this in your allocation logic:

\begin{verbatim}
use alignment_utils
integer :: m, padded_m
real(real64), allocatable :: A(:)

m = 1000
padded_m = padded_size(m)
allocate(A(padded_m))
\end{verbatim}

This ensures alignment across 1D, 2D, or ND arrays by applying padding logic to each dimension before allocation.

\subsection{Alignment-Aware Allocation for ND Arrays}

To ensure all dimensions are padded and aligned, wrap padding in a helper procedure or macro-like pattern per array rank. Example for 2D:

\begin{verbatim}
integer :: nx, ny, px, py
real(real64), allocatable :: A(:,:)

nx = 800
ny = 600
px = padded_size(nx)
py = padded_size(ny)
allocate(A(px, py))
\end{verbatim}

Repeat this pattern for higher-dimensional arrays.

\subsection{Note on Using Single Helper for Arbitrary Ranks}

It is not possible to pass arbitrary-rank assumed-shape arrays into a single routine that allocates them, because Fortran does not support polymorphic allocatable shapes. Instead, compute and apply padding for each dimension prior to allocation, using `padded\_size`.

Thus, the best practice is to:
\begin{itemize}
\item Store dimension sizes in variables.
\item Use \texttt{padded\_size()} for each.
\item Allocate directly in the relevant context.
\item Optionally provide \texttt{allocate\_padded\_1D()}, \texttt{...2D()} helpers per rank for clarity.
\end{itemize}

\subsection{Best Practice Summary}

\begin{itemize}
\item Use \texttt{!\$omp parallel do simd schedule(static)} to enable both thread and instruction-level parallelism.
\item Use compiler-specific alignment and vectorization flags in \texttt{fpm.toml}.
\item Dynamically set alignment to 32 or 64 via a shell script based on CPU capabilities.
\item Use \texttt{padded\_size()} to round up all dimensions to nearest alignment multiple.
\item Allocate arrays explicitly using padded sizes to ensure SIMD-safe alignment.
\item Maintain a \texttt{config} module to centralize the alignment parameter.
\end{itemize}

\subsection{Verifying Alignment at Runtime (Possible but \emph{not} practical)}

Intel and GNU compilers do not provide standard runtime alignment checks. For
debugging, one may use C interoperability and POSIX memory alignment checks
(advanced). For practical purposes, correct use of allocation and compiler
flags suffices.

\subsection{Conclusion: Thread-Level and CPU-Local Vectorized Parallelization}

By combining OpenMP, SIMD, and alignment-aware allocation, scientific Fortran code can achieve modern HPC-level efficiency while maintaining clarity and portability. This setup enables seamless transition to C bindings, WebAssembly targets, and multi-threaded environments such as browser-based Tensor Omics visualizations or clustered batch jobs.

\emph{Importantly}, the following Fortran code template enables \textbf{double parallelization}: first at the \textbf{thread level}, where array chunks are distributed across cores using the \texttt{!\$omp parallel do simd schedule(static)} directive; and second at the \textbf{instruction level}, where each thread processes its assigned chunk using vectorized CPU instructions enabled by the \texttt{simd} clause.

\subsection{Best Practice: SIMD in Leaf Loops, OpenMP in Top-Level Loops}

In Tensor Omics, it is crucial to distinguish between two levels of parallelization:

\begin{itemize}
\item \textbf{Thread-level parallelism}: achieved via \texttt{!\$omp parallel do} at the top level, typically when iterating over gene families or other large-scale, independent units of computation.
\item \textbf{Vector-level (SIMD) parallelism}: achieved via \texttt{!\$omp simd} within inner loops that perform the actual arithmetic operations, e.g., normalization, centroid computation, tensor updates.
\end{itemize}

\paragraph{Key rule:} \emph{Apply \texttt{!\$omp simd} only at the level of the loop that does the actual vector arithmetic. This is the most nested loop — the ``leaf'' loop.}

\paragraph{And:} \emph{Apply \texttt{!\$omp parallel do} only at the top level, for instance over gene families or modules.} This should be confirmed and coordinated with the software architect (Vivian or Asis) to ensure it aligns with the design of the specific routine.

\subsubsection{Why?}

Nested use of \texttt{simd} inside a loop that is already marked with \texttt{parallel do simd} leads to undefined or inefficient behavior. While technically allowed by OpenMP, compilers may:

\begin{itemize}
\item silently ignore the inner \texttt{simd} region,
\item fail to vectorize at all,
\item or generate scalar fallback code.
\end{itemize}

Hence, we \emph{do not} use both \texttt{parallel do simd} and inner \texttt{simd} together — unless there is a specific, performance-tested reason.

\subsubsection{Incorrect (nested SIMD, should be avoided)}

\begin{verbatim}
subroutine family_centroids(...)
  !$omp simd aligned(a, b, c:64)
  do j = 1, ndim
    ...
  end do
end subroutine

!The below repeated 'simd' is the problem here:
!$omp parallel do simd schedule(static) private(i)
do i = 1, nfam
  call family_centroids(...)
end do
\end{verbatim}

\textbf{Problems:}
\begin{itemize}
\item The outer loop redundantly specifies both \texttt{parallel do} and \texttt{simd}, causing potential nested vectorization issues.
\item The alignment is hardcoded (\texttt{64}) instead of using the macro defined in our configuration header.
\end{itemize}

\subsubsection{Correct and recommended pattern in Tensor Omics}

\begin{verbatim}
subroutine family_centroids(...)
  !$omp simd aligned(a, b, c:64) private(j)
  do j = 1, ndim
    ...
  end do
end subroutine

!$omp parallel do schedule(static) private(i) aligned(...)
do i = 1, nfam
  call family_centroids(...)
end do
\end{verbatim}

\emph{Note}, see section \ref{simd_architecture_macros} for details on how to
set the correct memory alignment boundary in bytes, e.g. ``\texttt{aligned(a,
b, c:64}'' and ``\texttt{!DIR\$ ASSUME\_ALIGNED a:64, b:64, c:64}'' to 16, 32,
64, or 128, using precompiler macros.

\textbf{This is the canonical Tensor Omics pattern:}
\begin{itemize}
\item The leaf loop that performs arithmetic (e.g., element-wise ops) uses \texttt{simd} and the \texttt{aligned(...:DEFAULT\_ALIGNMENT)} directive. This macro is defined in the precompiler header \texttt{precompiler\_constants.F90}.
\item The outer loop over independent entities (e.g., gene families) uses \texttt{parallel do} for thread-level parallelism.
\end{itemize}

\paragraph{Important:} Always use \texttt{\#include "precompiler\_constants.F90"} if alignment is to be ensured. This file defines \texttt{DEFAULT\_ALIGNMENT}, which is passed at compile time via the build script depending on AVX512, AVX2, or baseline SIMD capabilities. Using this macro ensures correct alignment in both \texttt{!DIR\$ ASSUME\_ALIGNED} and \texttt{aligned(...)} clauses.

\subsubsection{Summary}

\begin{itemize}
\item \textbf{Use \texttt{!\$omp simd} only in the leaf loop doing actual vector math.}
\item \textbf{Use \texttt{!\$omp parallel do} only in top-level outer loops.}
\item \textbf{Avoid using \texttt{parallel do simd} in Tensor Omics unless explicitly reviewed.}
\item \textbf{Always include \texttt{precompiler\_constants.F90} if using alignment directives.}
\item \textbf{Use correct directives to keep hardware compatibility across
  compilers and targets:}
  \begin{itemize}
    \item \texttt{aligned(...:<DEFAULT\_ALIGNMENT>)} \emph{and}
    \item \texttt{!DIR\$ ASSUME\_ALIGNED a:<DEFAULT\_ALIGNMENT>,
      b:<DEFAULT\_ALIGNMENT>, c:<DEFAULT\_ALIGNMENT>}.
  \end{itemize}
\end{itemize}

\subsection{Distributed Parallelism with Coarrays and OpenMP SIMD Loops}

This section describes how Tensor Omics achieves \textbf{triple parallelization} on distributed systems by combining:

\begin{itemize}
  \item \textbf{Coarrays} for inter-node (inter-image) parallelism,
  \item \textbf{OpenMP threads} for intra-node (core-level) parallelism,
  \item and \textbf{SIMD vectorization} for CPU-instruction-level efficiency.
\end{itemize}

This hybrid model enables high-throughput omics analysis on SLURM clusters with minimal programming overhead and near-optimal hardware utilization.

\subsubsection{Local Data Strategy in Coarrays}
Coarrays in Fortran natively represent distributed memory: each \emph{image} is conceptually an independent process with its own memory space. This makes them ideal for Tensor Omics, where data can be split into families and processed independently. 

The key principle is:
\begin{quote}
\textbf{Each image works on its own local subset of gene families.} Data from other images is only accessed explicitly when needed.
\end{quote}

Within each image, we apply the previously described memory-optimized loops with:
\begin{itemize}
\item \texttt{!\$omp parallel do simd} — enabling OpenMP threading and SIMD vectorization.
\item Intel pragmas and \texttt{aligned(...)} clauses — ensuring memory is aligned to AVX boundaries.
\end{itemize}

Crucially, \textbf{looping over coarrays automatically refers to the local image's data}, without additional indexing or copying, unless explicitly accessing remote images (e.g., \texttt{b[2]} to read from image 2).

\subsection{Brief summary: Declaring and Accessing Coarrays}

A coarray is declared in Fortran by appending square brackets with \texttt{[*]} to the variable declaration. For example:

\begin{verbatim}
real(real64), allocatable :: a(:)[:], b(:)[:], c(:)[:]
\end{verbatim}

The colon \texttt{:} indicates a deferred-shape (allocatable) array, and the brackets \texttt{[:]} declare the variable as a coarray, with one instance per image.

\textbf{Local image access} is performed without brackets:
\begin{verbatim}
a(i) = b(i) + c(i)        ! Local access: all references are to this_image()
\end{verbatim}

\textbf{Remote image access} uses explicit brackets with an image number:
\begin{verbatim}
a(i) = b(i)[2] + c(i)     ! Reads from image 2 (remote access)
\end{verbatim}

Remote access should be minimized for performance and memory locality. Tensor Omics encourages access to remote images only in explicitly synchronized stages.

Memory-aligned OpenMP SIMD loops work identically with coarrays when accessing only local data. The compiler automatically uses the correct memory region without copying:

\begin{verbatim}
!DIR$ ASSUME_ALIGNED a:64, b:64, c:64
!$omp parallel do simd schedule(static) aligned(a, b, c:64)
do i = 1, n
  a(i) = b(i) + c(i)       ! Local data access on this_image()
end do
!$omp end parallel do simd
\end{verbatim}

\subsubsection{Data Loading Based on Image ID}
The image-specific data loading follows a simple naming convention: each image loads its own chunk from a directory or file pattern like \texttt{<base>\_<image\_no>}.

Example:
\begin{verbatim}
integer :: me
me = this_image()

! Allocate coarrays as needed (e.g., expression vectors)
! Each image loads only its own data:
call load_txdata(me, base_file_name, expression_vecs, ...)
\end{verbatim}

This pattern supports full scalability with large gene family datasets. For best performance:
\begin{itemize}
\item Split data by gene family.
\item Assign families evenly to images during pre-processing.
\item Avoid inter-image data transfer unless strictly required.
\end{itemize}

\subsubsection{Synchronization and Remote Data Access}
Coarray images execute asynchronously by default. To coordinate across images:

\begin{itemize}
\item Use \texttt{sync all} to wait for all images at the same code line.
\item Use \texttt{sync images(*)} or \texttt{sync images(img)} for partial synchronization.
\item Access remote coarray data using bracket syntax (e.g., \texttt{vec(1:n)[2]}).
\end{itemize}

If cross-image data is required for analysis (e.g., inter-family comparisons):
\begin{itemize}
\item \textbf{Fetch remote data explicitly} using coarray brackets.
\item \textbf{Copy into aligned local arrays} before processing, preserving SIMD efficiency.
\item Perform \texttt{sync all} if necessary.
\end{itemize}

Memory budgeting must ensure that any fetched data fits into local memory.

\subsubsection{Compiling for Coarrays}
Compilation differs slightly depending on compiler:

\paragraph{With Intel (ifx/ifort):}
\begin{verbatim}
ifx -coarray=distributed -fopenmp -O3 -qopenmp -align array64byte -c file.f90
\end{verbatim}

\paragraph{With GNU gfortran + OpenCoarrays:}
\begin{verbatim}
caf -fcoarray=single -fopenmp -O3 -march=native -c file.f90
\end{verbatim}

Linking must include coarray runtimes, especially when using OpenCoarrays (\texttt{caf} handles this).

\subsubsection{SLURM Setup for Coarray Execution}

Below is a complete SLURM job script to run Tensor Omics with \textbf{3 Coarray images}, each using \textbf{40 OpenMP threads}. Adjust resource counts to your system and dataset.

\begin{verbatim}
#!/bin/bash
#SBATCH --job-name=tensor-omics
#SBATCH --nodes=3
#SBATCH --ntasks-per-node=1            # One Coarray image per node
#SBATCH --cpus-per-task=40             # 40 threads per image
#SBATCH --time=02:00:00
#SBATCH --partition=compute
#SBATCH --exclusive                    # Optional: gets full nodes
#SBATCH --output=slurm-%j.out
#SBATCH --error=slurm-%j.err

# Load modules (adjust to your environment)
module load intel/2023.1
module load openmpi/4.1.5              # or Intel MPI if using ifx/ifort

# Set OpenMP thread count
export OMP_NUM_THREADS=40
export FOR_COARRAY_NUM_IMAGES=3        # Optional: Intel Coarrays only

# Optional: pin threads for reproducibility and performance
export KMP_AFFINITY=granularity=fine,compact,1,0
export KMP_STACKSIZE=2g

# Run executable with MPI wrapper
srun ./tensor_omics_exe
\end{verbatim}

\paragraph{Notes:}
\begin{itemize}
\item Each image automatically processes only its local data.
\item Use \texttt{this\_image()} and \texttt{num\_images()} to manage indexing.
\item Combined with alignment-aware OpenMP SIMD loops, this setup provides maximal throughput.
\end{itemize}

\subsubsection{Conclusion}
The coarray-enabled, tripple-parallel architecture of Tensor Omics allows scalable, memory-aligned, and instruction-optimized analysis on both laptops and HPC clusters. Minimal code changes are needed to move from serial to multi-node execution. This enables true geometric tensor-based biology at scale.

\end{document}
